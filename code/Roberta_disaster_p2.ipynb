{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412ec8f0-cd2b-4705-8d50-d669b0f7a3a0",
   "metadata": {},
   "source": [
    "## Using Fine-Tuned Roberta Model on Unseen Data (Part 2)\n",
    "\n",
    "This script shows how to use fine-tuned Roberta model on new data to assign labels of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee72246-4432-46a7-8351-f30a5bc4bde9",
   "metadata": {},
   "source": [
    "#### Step 1: Download Packages & Data\n",
    "* make sure to do the **same data cleaning procedures** as for train data above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a05147da-0df7-49cd-9d8c-e9197a61326e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e759b90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments, RobertaForSequenceClassification, \\\n",
    "     RobertaTokenizerFast,DataCollatorWithPadding, pipeline\n",
    "from datasets import load_metric, Dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib.pylab import plt\n",
    "from numpy import arange\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1dc565-453c-4bce-a4e7-4f4c6c8780c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                text\n",
       "id                                                                  \n",
       "0                                 Just happened a terrible car crash\n",
       "2   Heard about #earthquake is different cities, stay safe everyone."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_data = pd.read_csv(\"test.csv\", index_col=0, nrows=50).drop(['keyword', 'location'], axis=1)\n",
    "unseen_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0608b6-080a-4fcb-af1c-216e58f2e27e",
   "metadata": {},
   "source": [
    "#### Step 2: Load Tokenizer & Create Pipeline Using Saved Model\n",
    "\n",
    "* the **pipeline** is made of tokenizer and model to use for prediction\n",
    "* we can now load our fine-tuned model from our directory\n",
    "* **'text-classification'** is an argument to specify the type of the pipeline\n",
    "* **link** specifies where model is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd6dfd1-de02-4c11-abc1-d64601d88026",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2c2300-9417-44e4-a317-b288adfdf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", \"./model_disaster/results\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd0d7ee-a15f-4636-af65-ca58042b2799",
   "metadata": {},
   "source": [
    "#### Step 3: Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72da67bb-2af3-4ee8-b37e-6b817e98b303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yess!!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prune_multple_consecutive_same_char(tweet_text):\n",
    "    '''\n",
    "    yesssssssss  is converted to yes\n",
    "    ssssssssssh is converted to ssh\n",
    "    '''\n",
    "    tweet_text = re.sub(r'(.)\\1+', r'\\1\\1', tweet_text)\n",
    "    return tweet_text\n",
    "\n",
    "prune_multple_consecutive_same_char(\"yessss!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef0f436-14e5-4bed-9df1-20fbd9a415e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove emoji\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3e3f3f-5804-4930-81e7-241ff0586184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = prune_multple_consecutive_same_char(text)\n",
    "    text = remove_emojis(text) \n",
    "    text = text.replace('\\\\n', '')\n",
    "    text = re.sub(r'http\\S+', '', text) \n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",'', text)\n",
    "    text = text.encode('ascii',errors='ignore').decode()\n",
    "    text = re.sub(\"^\\s+|\\s+$\", \"\", text, flags=re.UNICODE)\n",
    "    text = \" \".join(re.split(\"\\s+\", text, flags=re.UNICODE))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a876d8af-fb92-46bf-a705-efd0ebbe522f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                text  \\\n",
       "id                                                                     \n",
       "0                                 Just happened a terrible car crash   \n",
       "2   Heard about #earthquake is different cities, stay safe everyone.   \n",
       "\n",
       "                                                          clean_text  \n",
       "id                                                                    \n",
       "0                                 just happened a terrible car crash  \n",
       "2   heard about #earthquake is different cities, stay safe everyone.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_data.loc[:, \"clean_text\"] = unseen_data.loc[:, \"text\"].apply(clean_tweet)\n",
    "unseen_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4208d-c46f-492e-88f6-14a286fb2a83",
   "metadata": {},
   "source": [
    "#### Step 4: Run the Model\n",
    "\n",
    "* first try the model on a sample sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1798963b-7f53-4ffe-a44b-d7f75c33b2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 1, 'score': 0.898166298866272}]\n",
      "[{'label': 0, 'score': 0.8866080045700073}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe(\"there was a hurricane in georgia\"))\n",
    "print(pipe((\"I like ice-cream\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f7145-1143-438d-ac7a-4dfa11bb9577",
   "metadata": {},
   "source": [
    "* run the model and create dataframe to include the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f714813-6d98-4f69-8265-96601c6f529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = unseen_data[\"text\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "545c3aed-5e1d-418c-a6f7-d2ee02093f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd54fe8-1169-47e8-a7ec-ba9e2f304941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dict(sentences, preds):\n",
    "    results = []\n",
    "    for i, sent in enumerate(sentences):\n",
    "        prd = preds[i]\n",
    "        result = {}\n",
    "        result['clean_text'] = sent\n",
    "        result['label'] = prd['label']\n",
    "        result['score'] = prd['score']\n",
    "        results.append(result)\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9251a42-12cc-4c69-88d5-83bd56336292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = create_result_dict(sentences, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f68d8f-cb62-48a0-8b58-d29a4057a9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.928908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They'd probably still show more life than Arsenal did yesterday, eh? EH?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hey! How are you?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What a nice hat?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.927709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fuck off!</td>\n",
       "      <td>0</td>\n",
       "      <td>0.808605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         clean_text  \\\n",
       "0                                                                Just happened a terrible car crash   \n",
       "1                                  Heard about #earthquake is different cities, stay safe everyone.   \n",
       "2  there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all   \n",
       "3                                                          Apocalypse lighting. #Spokane #wildfires   \n",
       "4                                                     Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "5                                                                We're shaking...It's an earthquake   \n",
       "6                          They'd probably still show more life than Arsenal did yesterday, eh? EH?   \n",
       "7                                                                                 Hey! How are you?   \n",
       "8                                                                                  What a nice hat?   \n",
       "9                                                                                         Fuck off!   \n",
       "\n",
       "   label     score  \n",
       "0      1  0.915809  \n",
       "1      1  0.890740  \n",
       "2      1  0.931250  \n",
       "3      1  0.894984  \n",
       "4      1  0.928908  \n",
       "5      1  0.684168  \n",
       "6      0  0.846586  \n",
       "7      0  0.792071  \n",
       "8      0  0.927709  \n",
       "9      0  0.808605  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
